{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UWavy Navigation - Solution\n",
    "\n",
    "1. Overview\n",
    "2. Inertial Navigation\n",
    "3. Image Recognition\n",
    "4. Synthesis\n",
    "5. Conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy import misc\n",
    "from itertools import product, starmap\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import skimage\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.core.display import HTML\n",
    "import uwavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview (TODO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inertial Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a \"True\" Path\n",
    "\n",
    "Our coordinate system used in this simulation is simply the pixel grid of the reference image. This will be discussed in more detail in the image recognition section, but the inertial navigation system uses the same coordinates for simplicity. This coordinate system could be scaled or shifted linearly in any direction and with any magnitude, and our system would not be affected. The pixel grid was simply chosen for simplicity.\n",
    "\n",
    "The paths used by our simulation are generated by first generating an array of changes in displacement. We chose this method because it allows us to easily add systematic error to our simulation of the inertial measurement unit. In addition, is easy to construct complex shapes and paths with this method, because the changes in position will be constant, regardless of the absolute position of the drone.\n",
    "[TODO: Animation]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set out a path, starting at START_POS and following updates along DELTAS_TRUE\n",
    "start_pos = np.array([[1500,850]])\n",
    "deltas_true = (np.vstack((np.vstack([uwavy.s_turn(1) for _ in range(3)]), uwavy.wide_uturn(3))) * 25).astype(np.float64)\n",
    "path_true = np.cumsum(np.vstack((start_pos, deltas_true)), axis=0)\n",
    "\n",
    "## TODO Plot path_true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Systematic and Random Error\n",
    "[TODO: Animation]\n",
    "\n",
    "From our research of Inertial Measurement Units, we decided that there were two  types of errors that we wanted to simulate in order to faithfully simulate an actual IMU.\n",
    "1. The first type of error is systematic error, which would stem from the calibration of the unit not being accurate. For example, this could mean that the unit consistently measures that its momentum to the northeast is higher than it actually is, meaning its measured position is consistently more to the northeast. We simulate this by adding a constant error to every delta in the array. This error is usually small on a millitary quality drone, but over long periods of time, this type of error will invevitably show up. We tried to make our simulated error larger than we expect in practice.\n",
    "2. The other type of error is random error. This type of error would stem from the uncertainty of the unit. IMUs cannot have infinite precision, and so there will be some uncertainty. Like systemic error, on millitary quality drones, this will be small, but on long flights this error will compound. We simulated this error by adding a random error generated from a gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate some input from the onboard sensors and camera\n",
    "manhattan = uwavy.imread('manhattan.jpg')\n",
    "# Add systematically biased error \n",
    "deltas_sys_error = (deltas_true - np.array([3, -1])).astype(np.float64)\n",
    "#Add random error\n",
    "deltas_sys_and_rand = (deltas_true - np.random.random_sample(deltas_inert.shape))\n",
    "\n",
    "path_IMU = np.cumsum(np.vstack((start_pos, deltas_sys_and_rand)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ani = uwavy.FlightAnimator(manhattan, framerate=500)\n",
    "ani.addPath(path_true, label=\"True Path\", color=\"green\")\n",
    "ani.addPath(path_IMU, label=\"Simulated IMU measurement\", color=\"red\")\n",
    "HTML(ani.toHTML5Video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Recognition\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating the onboard camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img = load_image()\n",
    "img = take_picture(ref_img)\n",
    "plot(ref_img, img)\n",
    "# TODO subplots, side-by-side etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating the image database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read_img from PIL, or something\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching the database for the captured image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: heatmaps, etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informing the Search Algorithm\n",
    "1. Starting Point = from intertial nav\n",
    "1. Sprial Pattern\n",
    "1. Search Confidence\n",
    "### Combining Intertial + Image Recognition\n",
    "1. Putting the pieces together\n",
    "[Animation with both inertial + img rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = FlightAnimation()\n",
    "ani.add_target_start(path_true[0])\n",
    "ani.add_target_end(path_true[-1])\n",
    "ani.add_path(path_sim)\n",
    "ani.add_path(path_sim_plus)\n",
    "ani.start();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "[TODO: Make some over-generalizing statements]\n",
    "### Future Steps\n",
    "1. Increasing search radius dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
